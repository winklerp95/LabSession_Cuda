{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb028fc-9190-4e6c-be1b-ab7b7df7dfbb",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d52cedb-7810-463a-b5a1-24feabc25c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a4edc4-a664-4c08-b122-41a42ae3979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeTracker\n",
    "class TimeTracker:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "        print(\"############# Started Time Tracking:\", self.name, \"#############\")\n",
    "\n",
    "    def stop(self):\n",
    "        end_time = time.time()\n",
    "        duration = int((end_time - self.start_time) * 1000)\n",
    "\n",
    "        print(\"Duration:\", duration, \"ms\")\n",
    "        print(\"############# Stopped Time Tracking:\", self.name, \"#############\")\n",
    "\n",
    "        return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59493bce-2954-48c9-ba5b-ce4ece6891d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential matrix multiply\n",
    "def MatrixMultiplySeq(A, B):\n",
    "    matrix_size = A.size(0)\n",
    "    Result = torch.zeros((matrix_size, matrix_size))\n",
    "\n",
    "    for ROW in range(matrix_size):\n",
    "        for COL in range(matrix_size):\n",
    "            tmp_sum = 0\n",
    "            for i in range(matrix_size):\n",
    "                tmp_sum += A[ROW, i] * B[i, COL]\n",
    "            Result[ROW, COL] = tmp_sum\n",
    "\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc755d6e-71ea-4eda-b414-284ec0a8b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "Available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Check prerequisits\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff7237b-c6fb-4424-8ad4-02862e168a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  tensor([[0.1839, 0.8148, 0.3589,  ..., 0.5889, 0.0855, 0.7762],\n",
      "        [0.2786, 0.5245, 0.8086,  ..., 0.0329, 0.4164, 0.6768],\n",
      "        [0.9556, 0.5047, 0.2211,  ..., 0.1578, 0.7966, 0.4926],\n",
      "        ...,\n",
      "        [0.2736, 0.0969, 0.4181,  ..., 0.3368, 0.7930, 0.1242],\n",
      "        [0.8412, 0.9579, 0.2056,  ..., 0.9053, 0.7438, 0.9192],\n",
      "        [0.0948, 0.0088, 0.6437,  ..., 0.4494, 0.1825, 0.1127]])\n",
      "B:  tensor([[0.9794, 0.1497, 0.9190,  ..., 0.5045, 0.5841, 0.6646],\n",
      "        [0.3410, 0.3125, 0.8289,  ..., 0.1147, 0.4573, 0.5800],\n",
      "        [0.4055, 0.4458, 0.1741,  ..., 0.8753, 0.3773, 0.8459],\n",
      "        ...,\n",
      "        [0.3813, 0.7618, 0.0725,  ..., 0.9794, 0.1912, 0.1182],\n",
      "        [0.6624, 0.9045, 0.1557,  ..., 0.1353, 0.3082, 0.4754],\n",
      "        [0.4569, 0.4951, 0.5666,  ..., 0.9017, 0.1788, 0.2586]])\n"
     ]
    }
   ],
   "source": [
    "# Initialize size\n",
    "matrix_size = 1000\n",
    "\n",
    "# Create random values\n",
    "A = torch.rand(matrix_size, matrix_size)\n",
    "B = torch.rand(matrix_size, matrix_size)\n",
    "print(\"A: \", A)\n",
    "print(\"B: \", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19b722-589c-4721-bdbc-8aadd92e4524",
   "metadata": {},
   "source": [
    "# Run matrix multiplikation on CPU (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e54a69a-c2a9-44a1-a32d-8aafe193f7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Started Time Tracking: CPU Sequential #############\n",
      "Duration: 18755 ms\n",
      "############# Stopped Time Tracking: CPU Sequential #############\n",
      "Result:  tensor([[26.6406, 25.1083, 25.5114,  ..., 25.0780, 26.5163, 23.1867],\n",
      "        [28.0048, 28.2908, 26.9479,  ..., 25.4912, 26.7530, 25.1488],\n",
      "        [24.3587, 24.6768, 25.2260,  ..., 22.7775, 25.9049, 23.4128],\n",
      "        ...,\n",
      "        [26.1021, 24.8202, 25.7486,  ..., 24.5460, 23.8377, 23.4695],\n",
      "        [22.3583, 21.7431, 22.1539,  ..., 20.3475, 21.0651, 19.5448],\n",
      "        [26.8412, 26.5715, 25.6966,  ..., 24.4177, 26.0884, 24.8622]])\n"
     ]
    }
   ],
   "source": [
    "# This is really the stupid and long aproach, so the matrices are limited\n",
    "# You will see the reason in the duration time\n",
    "matrix_size_Seq = 100\n",
    "A_Cpu_Seq = A[:matrix_size_Seq, :matrix_size_Seq]\n",
    "B_Cpu_Seq = B[:matrix_size_Seq, :matrix_size_Seq]\n",
    "\n",
    "# Start tracker\n",
    "tracker = TimeTracker(\"CPU Sequential\")\n",
    "\n",
    "# Run Matrix Multiply on CPU (Sequential)\n",
    "result_Cpu_Seq = MatrixMultiplySeq(A_Cpu_Seq, B_Cpu_Seq)\n",
    "\n",
    "# Print results\n",
    "duration_Cpu_Seq =tracker.stop()\n",
    "print(\"Result: \", result_Cpu_Seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb68345-99cf-47ff-ab9f-8ffe2c28480c",
   "metadata": {},
   "source": [
    "# Exercise 1: Run custom kernel on GPU (Parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0680f694-972d-40a4-b4d8-77b7c75c3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prerequisits\n",
    "from torch.utils.cpp_extension import load\n",
    "import os\n",
    "os.environ['PATH'] += \";C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.37.32822\\\\bin\\\\Hostx64\\\\x64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dfe4d4c-c543-466a-ab63-9b4a176a19c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ninja available:  True\n"
     ]
    }
   ],
   "source": [
    "# Check prerequisits\n",
    "print(\"Ninja available: \",torch.utils.cpp_extension.is_ninja_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2aed4cd7-4b08-4eae-a675-8c7f4d97f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start load kernel\n",
      "Finish load kernel\n"
     ]
    }
   ],
   "source": [
    "# Load custom CUDA-Kernel\n",
    "print(\"Start load kernel\")\n",
    "CustomMatrixMultiply = load(\n",
    "    name=\"MatrixMultiply\",\n",
    "    sources=[\"MatrixMultiplyKernel.cu\"],\n",
    "    extra_cuda_cflags=[\"--expt-relaxed-constexpr\"]\n",
    "    # verbose=True # Activate for detail build output\n",
    ").MatrixMultiply\n",
    "print(\"Finish load kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9be18a3c-5685-4009-aadc-d45776cce8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Started Time Tracking: GPU_CustomKernel #############\n",
      "Duration: 191 ms\n",
      "############# Stopped Time Tracking: GPU_CustomKernel #############\n",
      "Result:  tensor([[253.9339, 250.9885, 249.6272,  ..., 261.6343, 248.2964, 252.8956],\n",
      "        [259.5894, 260.4133, 248.2497,  ..., 262.2768, 250.4139, 256.7153],\n",
      "        [246.5911, 249.2997, 237.7090,  ..., 255.3274, 246.4156, 236.3468],\n",
      "        ...,\n",
      "        [253.4617, 246.9597, 245.1122,  ..., 257.6799, 244.6112, 240.4261],\n",
      "        [258.8254, 257.8255, 249.5302,  ..., 258.0111, 249.5849, 246.4512],\n",
      "        [247.7889, 240.9982, 234.5899,  ..., 245.8352, 241.0048, 233.2119]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Start tracker\n",
    "tracker = TimeTracker(\"GPU_CustomKernel\")\n",
    "\n",
    "# Copy matrix to GPU\n",
    "# TODO: Copy matrix A to GPU, e.g. A_GPU_Custom = ...\n",
    "# Your Code here\n",
    "\n",
    "# TODO: Copy matrix B to GPU, e.g. B_GPU_Custom = ...\n",
    "# Your Code here\n",
    "\n",
    "# Allocate an matrix with zeros on GPU\n",
    "result_Gpu_Custom = torch.zeros(matrix_size, matrix_size).cuda()\n",
    "\n",
    "# TODO: Run CustomMatrixMultiply on GPU, e.g. CustomMatrixMultiply(...)\n",
    "# Your Code here \n",
    "\n",
    "# Print results\n",
    "duration_Gpu_Custom = tracker.stop()\n",
    "print(\"Result: \", result_Gpu_Custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cf3ce-535b-4ee3-b412-d90be4b8a049",
   "metadata": {},
   "source": [
    "# Exercise 2: Run matrix multipliktion on CPU (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea8b51c-4504-4f69-8757-30cc6fc24ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Started Time Tracking: CPU PyTorch #############\n",
      "Duration: 73 ms\n",
      "############# Stopped Time Tracking: CPU PyTorch #############\n",
      "Result:  tensor([[253.9340, 250.9885, 249.6272,  ..., 261.6343, 248.2964, 252.8955],\n",
      "        [259.5894, 260.4132, 248.2497,  ..., 262.2769, 250.4138, 256.7155],\n",
      "        [246.5911, 249.2997, 237.7092,  ..., 255.3273, 246.4155, 236.3471],\n",
      "        ...,\n",
      "        [253.4615, 246.9597, 245.1119,  ..., 257.6801, 244.6113, 240.4261],\n",
      "        [258.8253, 257.8257, 249.5302,  ..., 258.0111, 249.5849, 246.4514],\n",
      "        [247.7888, 240.9982, 234.5901,  ..., 245.8354, 241.0048, 233.2120]])\n"
     ]
    }
   ],
   "source": [
    "# Start tracker\n",
    "tracker = TimeTracker(\"CPU PyTorch\")\n",
    "\n",
    "# TODO: Run Matrix Multiply on CPU (Parallel), e.g. result_CPU_PyTorch = ...\n",
    "# Your Code here \n",
    "\n",
    "# Print results\n",
    "duration_Cpu_PyTorch = tracker.stop()\n",
    "print(\"Result: \", result_Cpu_PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2b070-942c-45dd-aa29-c9e9a9b9e606",
   "metadata": {},
   "source": [
    "# Exercise 3: Run matrix multiplikation on GPU (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf292d8-2c13-4c8b-be92-6390de1c03ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Started Time Tracking: GPU PyTorch #############\n",
      "Duration: 177 ms\n",
      "############# Stopped Time Tracking: GPU PyTorch #############\n",
      "Result:  tensor([[253.9339, 250.9885, 249.6272,  ..., 261.6343, 248.2964, 252.8956],\n",
      "        [259.5894, 260.4133, 248.2497,  ..., 262.2768, 250.4139, 256.7153],\n",
      "        [246.5911, 249.2997, 237.7090,  ..., 255.3274, 246.4156, 236.3468],\n",
      "        ...,\n",
      "        [253.4617, 246.9597, 245.1122,  ..., 257.6799, 244.6112, 240.4261],\n",
      "        [258.8254, 257.8255, 249.5302,  ..., 258.0111, 249.5849, 246.4512],\n",
      "        [247.7889, 240.9982, 234.5899,  ..., 245.8352, 241.0048, 233.2119]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Start tracker\n",
    "tracker = TimeTracker(\"GPU PyTorch\")\n",
    "\n",
    "# Copy matrix to GPU\n",
    "# TODO: Copy matrix A to GPU, e.g. A_Gpu_PyTorch = ...\n",
    "# Your Code here\n",
    "\n",
    "# TODO: Copy matrix B to GPU, e.g. B_Gpu_PyTorch = ...\n",
    "# Your Code here\n",
    "\n",
    "# TODO: Run Matrix Multiply on GPU (Parallel), e.g. result_GPU_PyTorch = ...\n",
    "# Your Code here \n",
    "\n",
    "# Print results\n",
    "duration_Gpu_PyTorch = tracker.stop()\n",
    "print(\"Result: \", result_Gpu_PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406cc4c-7d83-4402-8e27-160233b8e6ef",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01cfd519-4121-4df2-9221-722072713f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix size:  1000\n",
      "A:  tensor([[0.1839, 0.8148, 0.3589,  ..., 0.5889, 0.0855, 0.7762],\n",
      "        [0.2786, 0.5245, 0.8086,  ..., 0.0329, 0.4164, 0.6768],\n",
      "        [0.9556, 0.5047, 0.2211,  ..., 0.1578, 0.7966, 0.4926],\n",
      "        ...,\n",
      "        [0.2736, 0.0969, 0.4181,  ..., 0.3368, 0.7930, 0.1242],\n",
      "        [0.8412, 0.9579, 0.2056,  ..., 0.9053, 0.7438, 0.9192],\n",
      "        [0.0948, 0.0088, 0.6437,  ..., 0.4494, 0.1825, 0.1127]])\n",
      "B:  tensor([[0.9794, 0.1497, 0.9190,  ..., 0.5045, 0.5841, 0.6646],\n",
      "        [0.3410, 0.3125, 0.8289,  ..., 0.1147, 0.4573, 0.5800],\n",
      "        [0.4055, 0.4458, 0.1741,  ..., 0.8753, 0.3773, 0.8459],\n",
      "        ...,\n",
      "        [0.3813, 0.7618, 0.0725,  ..., 0.9794, 0.1912, 0.1182],\n",
      "        [0.6624, 0.9045, 0.1557,  ..., 0.1353, 0.3082, 0.4754],\n",
      "        [0.4569, 0.4951, 0.5666,  ..., 0.9017, 0.1788, 0.2586]])\n",
      "Result:  tensor([[253.9339, 250.9885, 249.6272,  ..., 261.6343, 248.2964, 252.8956],\n",
      "        [259.5894, 260.4133, 248.2497,  ..., 262.2768, 250.4139, 256.7153],\n",
      "        [246.5911, 249.2997, 237.7090,  ..., 255.3274, 246.4156, 236.3468],\n",
      "        ...,\n",
      "        [253.4617, 246.9597, 245.1122,  ..., 257.6799, 244.6112, 240.4261],\n",
      "        [258.8254, 257.8255, 249.5302,  ..., 258.0111, 249.5849, 246.4512],\n",
      "        [247.7889, 240.9982, 234.5899,  ..., 245.8352, 241.0048, 233.2119]],\n",
      "       device='cuda:0')\n",
      "Duration CPU - Limited to 100x100 Matrix (Sequential):  18755 ms\n",
      "Duration GPU Custom (Parallel):  191 ms\n",
      "Duration CPU PyTorch (Parallel):  73 ms\n",
      "Duration GPU PyTorch (Parallel):  177 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix size: \", matrix_size)\n",
    "print(\"A: \", A)\n",
    "print(\"B: \", B)\n",
    "print(\"Result: \", result_Gpu_PyTorch)\n",
    "print(\"Duration CPU - Limited to 100x100 Matrix (Sequential): \", str(duration_Cpu_Seq) + \" ms\")\n",
    "print(\"Duration GPU Custom (Parallel): \", str(duration_Gpu_Custom) + \" ms\")\n",
    "print(\"Duration CPU PyTorch (Parallel): \", str(duration_Cpu_PyTorch) + \" ms\")\n",
    "print(\"Duration GPU PyTorch (Parallel): \", str(duration_Gpu_PyTorch) + \" ms\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeedabe-9090-4f21-9113-9f8a7ed4bdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
