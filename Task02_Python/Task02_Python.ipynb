{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feb028fc-9190-4e6c-be1b-ab7b7df7dfbb",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d52cedb-7810-463a-b5a1-24feabc25c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a4edc4-a664-4c08-b122-41a42ae3979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeTracker\n",
    "class TimeTracker:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.start_time = None\n",
    "        self.start()\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "        print(\"############# Started Time Tracking:\", self.name, \"#############\")\n",
    "\n",
    "    def stop(self):\n",
    "        end_time = time.time()\n",
    "        duration = int((end_time - self.start_time) * 1000)\n",
    "\n",
    "        print(\"Duration:\", duration, \"ms\")\n",
    "        print(\"############# Stopped Time Tracking:\", self.name, \"#############\")\n",
    "\n",
    "        return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59493bce-2954-48c9-ba5b-ce4ece6891d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential matrix multiply\n",
    "def MatrixMultiplySeq(A, B):\n",
    "    matrix_size = A.size(0)\n",
    "    Result = torch.zeros((matrix_size, matrix_size))\n",
    "\n",
    "    for ROW in range(matrix_size):\n",
    "        for COL in range(matrix_size):\n",
    "            tmp_sum = 0\n",
    "            for i in range(matrix_size):\n",
    "                tmp_sum += A[ROW, i] * B[i, COL]\n",
    "            Result[ROW, COL] = tmp_sum\n",
    "\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc755d6e-71ea-4eda-b414-284ec0a8b300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "Available GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# Check prerequisits\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7237b-c6fb-4424-8ad4-02862e168a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize size\n",
    "matrix_size = 1000\n",
    "\n",
    "# Create random values\n",
    "A = torch.rand(matrix_size, matrix_size)\n",
    "B = torch.rand(matrix_size, matrix_size)\n",
    "print(\"A: \", A)\n",
    "print(\"B: \", B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19b722-589c-4721-bdbc-8aadd92e4524",
   "metadata": {},
   "source": [
    "# Run matrix multiplikation on CPU (Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54a69a-c2a9-44a1-a32d-8aafe193f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is really the stupid and long aproach, so the matrices are limited\n",
    "# You will see the reason in the duration time\n",
    "matrix_size_Seq = 100\n",
    "A_Cpu_Seq = A[:matrix_size_Seq, :matrix_size_Seq]\n",
    "B_Cpu_Seq = B[:matrix_size_Seq, :matrix_size_Seq]\n",
    "\n",
    "# Start tracker\n",
    "tracker = TimeTracker(\"CPU Sequential\")\n",
    "\n",
    "# Run Matrix Multiply on CPU (Sequential)\n",
    "result_Cpu_Seq = MatrixMultiplySeq(A_Cpu_Seq, B_Cpu_Seq)\n",
    "\n",
    "# Print results\n",
    "duration_Cpu_Seq =tracker.stop()\n",
    "print(\"Result: \", result_Cpu_Seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb68345-99cf-47ff-ab9f-8ffe2c28480c",
   "metadata": {},
   "source": [
    "# Exercise 1: Run custom kernel on GPU (Parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To activate the development environment for the Microsoft Visual Studio C++ compiler with a 64-bit configuration and for compiling CUDA code the following command must be executed in the Terminal.\n",
    "1. File > New > Terminal\n",
    "2. Run: ```& \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Enterprise\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680f694-972d-40a4-b4d8-77b7c75c3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set prerequisits\n",
    "from torch.utils.cpp_extension import load\n",
    "import os\n",
    "os.environ['PATH'] += \";C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Enterprise\\\\VC\\\\Tools\\\\MSVC\\\\14.37.32822\\\\bin\\\\Hostx64\\\\x64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe4d4c-c543-466a-ab63-9b4a176a19c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check prerequisits\n",
    "print(\"Ninja available: \",torch.utils.cpp_extension.is_ninja_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed4cd7-4b08-4eae-a675-8c7f4d97f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom CUDA-Kernel\n",
    "print(\"Start load kernel\")\n",
    "CustomMatrixMultiply = load(\n",
    "    name=\"MatrixMultiply\",\n",
    "    sources=[\"MatrixMultiplyKernel.cu\"],\n",
    "    extra_cuda_cflags=[\"--expt-relaxed-constexpr\"]\n",
    "    # verbose=True # Activate for detail build output\n",
    ").MatrixMultiply\n",
    "print(\"Finish load kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be18a3c-5685-4009-aadc-d45776cce8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracker\n",
    "tracker = TimeTracker(\"GPU_CustomKernel\")\n",
    "\n",
    "# Copy matrix to GPU\n",
    "# TODO: Copy matrix A to GPU, e.g. A_GPU_Custom = ...\n",
    "# Your Code here\n",
    "\n",
    "# TODO: Copy matrix B to GPU, e.g. B_GPU_Custom = ...\n",
    "# Your Code here\n",
    "\n",
    "# Allocate an matrix with zeros on GPU\n",
    "result_Gpu_Custom = torch.zeros(matrix_size, matrix_size).cuda()\n",
    "\n",
    "# TODO: Run CustomMatrixMultiply on GPU, e.g. CustomMatrixMultiply(...)\n",
    "# Your Code here \n",
    "\n",
    "# Print results\n",
    "duration_Gpu_Custom = tracker.stop()\n",
    "print(\"Result: \", result_Gpu_Custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cf3ce-535b-4ee3-b412-d90be4b8a049",
   "metadata": {},
   "source": [
    "# Exercise 2: Run matrix multipliktion on CPU (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea8b51c-4504-4f69-8757-30cc6fc24ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracker\n",
    "tracker = TimeTracker(\"CPU PyTorch\")\n",
    "\n",
    "# TODO: Run Matrix Multiply on CPU (Parallel), e.g. result_CPU_PyTorch = ...\n",
    "# Your Code here \n",
    "\n",
    "# Print results\n",
    "duration_Cpu_PyTorch = tracker.stop()\n",
    "print(\"Result: \", result_Cpu_PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a2b070-942c-45dd-aa29-c9e9a9b9e606",
   "metadata": {},
   "source": [
    "# Exercise 3: Run matrix multiplikation on GPU (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf292d8-2c13-4c8b-be92-6390de1c03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tracker\n",
    "tracker = TimeTracker(\"GPU PyTorch\")\n",
    "\n",
    "# Copy matrix to GPU\n",
    "# TODO: Copy matrix A to GPU, e.g. A_Gpu_PyTorch = ...\n",
    "# Your Code here\n",
    "\n",
    "# TODO: Copy matrix B to GPU, e.g. B_Gpu_PyTorch = ...\n",
    "# Your Code here\n",
    "\n",
    "# TODO: Run Matrix Multiply on GPU (Parallel), e.g. result_GPU_PyTorch = ...\n",
    "# Your Code here \n",
    "\n",
    "# Print results\n",
    "duration_Gpu_PyTorch = tracker.stop()\n",
    "print(\"Result: \", result_Gpu_PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5406cc4c-7d83-4402-8e27-160233b8e6ef",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cfd519-4121-4df2-9221-722072713f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matrix size: \", matrix_size)\n",
    "print(\"A: \", A)\n",
    "print(\"B: \", B)\n",
    "print(\"Result: \", result_Gpu_PyTorch)\n",
    "print(\"Duration CPU - Limited to 100x100 Matrix (Sequential): \", str(duration_Cpu_Seq) + \" ms\")\n",
    "print(\"Duration GPU Custom (Parallel): \", str(duration_Gpu_Custom) + \" ms\")\n",
    "print(\"Duration CPU PyTorch (Parallel): \", str(duration_Cpu_PyTorch) + \" ms\")\n",
    "print(\"Duration GPU PyTorch (Parallel): \", str(duration_Gpu_PyTorch) + \" ms\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeedabe-9090-4f21-9113-9f8a7ed4bdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
